{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\anaconda3\\envs\\vision\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: -PKG-VERSION is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as fn\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from models.models import LPCNNv1\n",
    "\n",
    "from src.data.car_plate_dataset import UFPRDataset, id_to_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Arya\\\\workspace\\\\ProjectSentry\\\\data\\\\raw\\\\UFPR-ALPR dataset\\\\testing\\\\track0091'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"C:/Users/Arya/workspace/ProjectSentry/data/raw/UFPR-ALPR dataset/testing/track0091\")\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished setting up data\n"
     ]
    }
   ],
   "source": [
    "train_dataset = UFPRDataset(\n",
    "    \"C:\\\\Users\\\\Arya\\\\workspace\\\\ProjectSentry\\\\data\\\\raw\\\\UFPR-ALPR dataset\\\\training\",\n",
    "    resize=torchvision.transforms.Resize(size=500),\n",
    "    grayscale=torchvision.transforms.Grayscale()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1152,  506, 1209,  531])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset.labels.items()\n",
    "# train_dataset.__getitem__(29)\n",
    "# train_dataset.labels[\"000130\"][1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: C:\\Users\\Arya\\workspace\\ProjectSentry\\data\\raw\\UFPR-ALPR dataset\\training\\track0028\\lightning_logs\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | conv1        | Conv2d     | 832   \n",
      "1 | rel1         | ReLU       | 0     \n",
      "2 | conv2        | Conv2d     | 51.3 K\n",
      "3 | rel2         | ReLU       | 0     \n",
      "4 | pool         | MaxPool2d  | 0     \n",
      "5 | flatten      | Flatten    | 0     \n",
      "6 | dense        | Linear     | 13.9 M\n",
      "7 | rel3         | ReLU       | 0     \n",
      "8 | bounding_box | Sequential | 772   \n",
      "--------------------------------------------\n",
      "13.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.9 M    Total params\n",
      "55.631    Total estimated model params size (MB)\n",
      "C:\\Users\\Arya\\anaconda3\\envs\\vision\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77ae8ef304174caf94abae87a9b1872c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500, 888])\n",
      "tensor([-0.0170,  0.0270,  0.0136, -0.0617], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 242, 455, 257]], dtype=torch.int32)\n",
      "tensor(343.7595, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\workspace\\ProjectSentry\\models\\models.py:83: UserWarning: Using a target size (torch.Size([1, 4])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.l1_loss(predicted_bb, target_bb[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500, 888])\n",
      "tensor([0.0726, 0.1003, 0.0939, 0.0075], grad_fn=<MeanBackward1>)\n",
      "tensor([[423, 242, 457, 256]], dtype=torch.int32)\n",
      "tensor(344.4314, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([0.2295, 0.2470, 0.2482, 0.1496], grad_fn=<MeanBackward1>)\n",
      "tensor([[425, 241, 460, 255]], dtype=torch.int32)\n",
      "tensor(345.0314, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([0.4680, 0.4738, 0.4821, 0.3712], grad_fn=<MeanBackward1>)\n",
      "tensor([[428, 240, 462, 254]], dtype=torch.int32)\n",
      "tensor(345.5512, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([0.7943, 0.7869, 0.8025, 0.6797], grad_fn=<MeanBackward1>)\n",
      "tensor([[430, 240, 464, 254]], dtype=torch.int32)\n",
      "tensor(346.2341, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([1.2130, 1.1915, 1.2145, 1.0798], grad_fn=<MeanBackward1>)\n",
      "tensor([[432, 240, 466, 254]], dtype=torch.int32)\n",
      "tensor(346.8253, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([1.7283, 1.6924, 1.7226, 1.5764], grad_fn=<MeanBackward1>)\n",
      "tensor([[435, 241, 468, 255]], dtype=torch.int32)\n",
      "tensor(348.0701, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([2.3450, 2.2941, 2.3316, 2.1738], grad_fn=<MeanBackward1>)\n",
      "tensor([[437, 242, 470, 256]], dtype=torch.int32)\n",
      "tensor(348.9639, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([3.0674, 3.0012, 3.0459, 2.8767], grad_fn=<MeanBackward1>)\n",
      "tensor([[440, 244, 473, 257]], dtype=torch.int32)\n",
      "tensor(350.5022, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([3.9002, 3.8184, 3.8704, 3.6896], grad_fn=<MeanBackward1>)\n",
      "tensor([[443, 244, 475, 258]], dtype=torch.int32)\n",
      "tensor(351.1803, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([4.8481, 4.7502, 4.8096, 4.6172], grad_fn=<MeanBackward1>)\n",
      "tensor([[446, 245, 478, 258]], dtype=torch.int32)\n",
      "tensor(351.9937, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([5.9156, 5.8014, 5.8681, 5.6641], grad_fn=<MeanBackward1>)\n",
      "tensor([[450, 245, 481, 258]], dtype=torch.int32)\n",
      "tensor(352.6877, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([7.1072, 6.9764, 7.0506, 6.8348], grad_fn=<MeanBackward1>)\n",
      "tensor([[453, 244, 484, 258]], dtype=torch.int32)\n",
      "tensor(352.7578, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([8.4276, 8.2799, 8.3615, 8.1340], grad_fn=<MeanBackward1>)\n",
      "tensor([[457, 244, 488, 257]], dtype=torch.int32)\n",
      "tensor(353.1993, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([9.8813, 9.7164, 9.8056, 9.5661], grad_fn=<MeanBackward1>)\n",
      "tensor([[461, 244, 492, 256]], dtype=torch.int32)\n",
      "tensor(353.5077, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([11.4727, 11.2904, 11.3873, 11.1357], grad_fn=<MeanBackward1>)\n",
      "tensor([[465, 245, 495, 257]], dtype=torch.int32)\n",
      "tensor(354.1785, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([13.2065, 13.0064, 13.1110, 12.8473], grad_fn=<MeanBackward1>)\n",
      "tensor([[468, 244, 499, 256]], dtype=torch.int32)\n",
      "tensor(353.7072, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([15.0869, 14.8689, 14.9813, 14.7053], grad_fn=<MeanBackward1>)\n",
      "tensor([[472, 244, 503, 256]], dtype=torch.int32)\n",
      "tensor(353.8394, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([17.1185, 16.8823, 17.0025, 16.7141], grad_fn=<MeanBackward1>)\n",
      "tensor([[477, 244, 507, 255]], dtype=torch.int32)\n",
      "tensor(353.8206, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([19.3056, 19.0509, 19.1791, 18.8782], grad_fn=<MeanBackward1>)\n",
      "tensor([[481, 242, 511, 254]], dtype=torch.int32)\n",
      "tensor(352.8965, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([21.6525, 21.3791, 21.5153, 21.2018], grad_fn=<MeanBackward1>)\n",
      "tensor([[486, 240, 515, 252]], dtype=torch.int32)\n",
      "tensor(351.8128, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([24.1634, 23.8711, 24.0154, 23.6891], grad_fn=<MeanBackward1>)\n",
      "tensor([[490, 237, 520, 250]], dtype=torch.int32)\n",
      "tensor(350.3152, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([26.8426, 26.5312, 26.6836, 26.3444], grad_fn=<MeanBackward1>)\n",
      "tensor([[495, 234, 525, 248]], dtype=torch.int32)\n",
      "tensor(348.8996, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([29.6941, 29.3633, 29.5240, 29.1718], grad_fn=<MeanBackward1>)\n",
      "tensor([[500, 232, 529, 246]], dtype=torch.int32)\n",
      "tensor(347.3117, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([32.7220, 32.3716, 32.5407, 32.1753], grad_fn=<MeanBackward1>)\n",
      "tensor([[504, 231, 533, 244]], dtype=torch.int32)\n",
      "tensor(345.5476, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([35.9303, 35.5601, 35.7376, 35.3589], grad_fn=<MeanBackward1>)\n",
      "tensor([[509, 230, 538, 244]], dtype=torch.int32)\n",
      "tensor(344.6033, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([39.3228, 38.9327, 39.1187, 38.7266], grad_fn=<MeanBackward1>)\n",
      "tensor([[514, 230, 544, 244]], dtype=torch.int32)\n",
      "tensor(343.9748, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([42.9035, 42.4931, 42.6877, 42.2821], grad_fn=<MeanBackward1>)\n",
      "tensor([[520, 230, 549, 244]], dtype=torch.int32)\n",
      "tensor(343.1584, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([46.6760, 46.2452, 46.4485, 46.0292], grad_fn=<MeanBackward1>)\n",
      "tensor([[526, 233, 554, 245]], dtype=torch.int32)\n",
      "tensor(343.1503, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([50.6440, 50.1926, 50.4046, 49.9716], grad_fn=<MeanBackward1>)\n",
      "tensor([[532, 233, 559, 246]], dtype=torch.int32)\n",
      "tensor(342.1968, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([54.8110, 54.3389, 54.5596, 54.1128], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 438, 219]], dtype=torch.int32)\n",
      "tensor(263.7944, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([59.1806, 58.6875, 58.9171, 58.4563], grad_fn=<MeanBackward1>)\n",
      "tensor([[407, 208, 438, 218]], dtype=torch.int32)\n",
      "tensor(258.9396, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([63.7561, 63.2419, 63.4804, 63.0055], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 207, 438, 218]], dtype=torch.int32)\n",
      "tensor(254.3790, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([68.5408, 68.0053, 68.2528, 67.7637], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 439, 219]], dtype=torch.int32)\n",
      "tensor(250.3593, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([73.5380, 72.9809, 73.2376, 72.7342], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 438, 219]], dtype=torch.int32)\n",
      "tensor(245.1273, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([78.7507, 78.1720, 78.4378, 77.9200], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 439, 219]], dtype=torch.int32)\n",
      "tensor(240.1799, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([84.1819, 83.5815, 83.8565, 83.3241], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 439, 220]], dtype=torch.int32)\n",
      "tensor(235.0140, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([89.8348, 89.2123, 89.4966, 88.9496], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 439, 220]], dtype=torch.int32)\n",
      "tensor(229.3767, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([95.7119, 95.0674, 95.3610, 94.7993], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 209, 439, 221]], dtype=torch.int32)\n",
      "tensor(224.0151, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([101.8162, 101.1494, 101.4524, 100.8759], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 209, 440, 221]], dtype=torch.int32)\n",
      "tensor(218.1765, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([108.1503, 107.4611, 107.7735, 107.1822], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 209, 440, 221]], dtype=torch.int32)\n",
      "tensor(211.8582, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([114.7168, 114.0050, 114.3270, 113.7206], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 209, 440, 220]], dtype=torch.int32)\n",
      "tensor(205.0577, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([121.5181, 120.7837, 121.1152, 120.4938], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(198.0223, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([128.5568, 127.7995, 128.1406, 127.5041], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(190.9997, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([135.8351, 135.0549, 135.4057, 134.7539], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(183.7376, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([143.3552, 142.5520, 142.9126, 142.2453], grad_fn=<MeanBackward1>)\n",
      "tensor([[408, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(176.2337, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([151.1195, 150.2930, 150.6634, 149.9808], grad_fn=<MeanBackward1>)\n",
      "tensor([[407, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(168.2358, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([159.1299, 158.2801, 158.6602, 157.9622], grad_fn=<MeanBackward1>)\n",
      "tensor([[407, 208, 440, 219]], dtype=torch.int32)\n",
      "tensor(159.9919, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([167.3885, 166.5153, 166.9054, 166.1917], grad_fn=<MeanBackward1>)\n",
      "tensor([[407, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(151.9998, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([175.8972, 175.0004, 175.4004, 174.6711], grad_fn=<MeanBackward1>)\n",
      "tensor([[407, 208, 440, 220]], dtype=torch.int32)\n",
      "tensor(143.5077, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([184.6579, 183.7375, 184.1475, 183.4024], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 208, 439, 220]], dtype=torch.int32)\n",
      "tensor(134.2637, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([193.6723, 192.7282, 193.1482, 192.3874], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 208, 439, 220]], dtype=torch.int32)\n",
      "tensor(125.2660, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([202.9424, 201.9745, 202.4045, 201.6278], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 208, 438, 220]], dtype=torch.int32)\n",
      "tensor(115.7627, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([212.4697, 211.4778, 211.9179, 211.1254], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 208, 438, 220]], dtype=torch.int32)\n",
      "tensor(107.7412, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([222.0627, 219.8183, 221.4974, 220.6895], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 209, 438, 221]], dtype=torch.int32)\n",
      "tensor(102.6422, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([231.7343, 227.0842, 231.1559, 230.3332], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 209, 437, 221]], dtype=torch.int32)\n",
      "tensor(101.3818, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([241.1939, 233.0677, 240.6035, 238.4924], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 209, 437, 221]], dtype=torch.int32)\n",
      "tensor(100.1907, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([250.4570, 237.8688, 249.8553, 245.2776], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 209, 436, 222]], dtype=torch.int32)\n",
      "tensor(97.7085, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([259.5392, 241.5885, 258.9275, 250.8015], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 210, 436, 222]], dtype=torch.int32)\n",
      "tensor(95.2308, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([268.4573, 244.3255, 267.8363, 255.1759], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 210, 435, 222]], dtype=torch.int32)\n",
      "tensor(92.3020, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([277.2287, 246.1752, 276.5988, 258.5092], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 215, 435, 230]], dtype=torch.int32)\n",
      "tensor(83.4642, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([285.8706, 247.2280, 285.2327, 260.9049], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 216, 435, 231]], dtype=torch.int32)\n",
      "tensor(79.5074, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([294.4017, 247.5685, 293.7560, 262.4606], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 216, 436, 232]], dtype=torch.int32)\n",
      "tensor(75.7179, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([302.8403, 247.2756, 302.1873, 263.2674], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 217, 436, 232]], dtype=torch.int32)\n",
      "tensor(71.3789, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([311.2056, 246.4216, 310.5459, 263.4092], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 217, 436, 233]], dtype=torch.int32)\n",
      "tensor(66.7698, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([319.5171, 245.0730, 318.8510, 262.9633], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 216, 437, 232]], dtype=torch.int32)\n",
      "tensor(63.1671, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([327.7943, 243.2899, 327.1219, 261.9998], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 216, 437, 232]], dtype=torch.int32)\n",
      "tensor(58.3434, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([336.0576, 241.1267, 335.3791, 260.5827], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 215, 437, 231]], dtype=torch.int32)\n",
      "tensor(53.8182, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([344.3265, 238.6321, 343.6419, 258.7689], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 215, 438, 231]], dtype=torch.int32)\n",
      "tensor(48.8582, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([352.6216, 235.8495, 351.9312, 256.6100], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 215, 438, 231]], dtype=torch.int32)\n",
      "tensor(43.7267, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([360.9631, 232.8173, 360.2668, 254.1515], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 214, 438, 231]], dtype=torch.int32)\n",
      "tensor(38.4347, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([369.3712, 229.5690, 368.6690, 251.4333], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 215, 439, 231]], dtype=torch.int32)\n",
      "tensor(32.7405, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([377.8661, 226.1340, 377.1577, 248.4910], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 214, 439, 231]], dtype=torch.int32)\n",
      "tensor(27.1503, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([386.4676, 222.5377, 385.7533, 245.3550], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 214, 439, 230]], dtype=torch.int32)\n",
      "tensor(21.4179, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([395.1955, 218.8012, 394.4749, 242.0517], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 214, 439, 230]], dtype=torch.int32)\n",
      "tensor(15.5456, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([404.0692, 214.9430, 403.3421, 238.6036], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 214, 439, 229]], dtype=torch.int32)\n",
      "tensor(13.5684, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([410.9352, 210.5549, 411.5466, 234.5581], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 213, 440, 229]], dtype=torch.int32)\n",
      "tensor(12.8480, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([416.4266, 207.2769, 419.5829, 230.2457], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 213, 439, 229]], dtype=torch.int32)\n",
      "tensor(11.7031, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([420.6832, 204.9993, 427.4645, 225.6992], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 213, 439, 228]], dtype=torch.int32)\n",
      "tensor(11.6301, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([424.2951, 203.8426, 435.6785, 222.5260], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 212, 439, 228]], dtype=torch.int32)\n",
      "tensor(11.3120, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([427.3314, 203.6881, 444.2064, 220.5765], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 212, 438, 228]], dtype=torch.int32)\n",
      "tensor(13.3183, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([428.9365, 203.9997, 450.7329, 219.2554], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 212, 438, 228]], dtype=torch.int32)\n",
      "tensor(15.8536, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([429.2473, 204.7249, 455.4341, 218.4999], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 211, 437, 227]], dtype=torch.int32)\n",
      "tensor(16.8641, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([428.3956, 205.8130, 458.4823, 218.2479], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 210, 437, 226]], dtype=torch.int32)\n",
      "tensor(16.7042, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([426.5081, 207.2153, 460.0437, 218.4400], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 210, 436, 226]], dtype=torch.int32)\n",
      "tensor(16.7241, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([423.7046, 208.8860, 460.2763, 219.0199], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 209, 435, 225]], dtype=torch.int32)\n",
      "tensor(15.5188, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([420.0976, 210.7829, 459.3297, 219.9351], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 209, 434, 225]], dtype=torch.int32)\n",
      "tensor(14.8188, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([415.3909, 211.3957, 456.9026, 220.9244], grad_fn=<MeanBackward1>)\n",
      "tensor([[392, 210, 434, 225]], dtype=torch.int32)\n",
      "tensor(12.9412, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([409.7449, 210.8780, 453.1873, 221.9657], grad_fn=<MeanBackward1>)\n",
      "tensor([[392, 210, 433, 225]], dtype=torch.int32)\n",
      "tensor(10.4611, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([403.3042, 209.3745, 448.3607, 223.0358], grad_fn=<MeanBackward1>)\n",
      "tensor([[391, 210, 432, 225]], dtype=torch.int32)\n",
      "tensor(7.8136, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([396.5623, 208.4046, 442.9889, 224.3179], grad_fn=<MeanBackward1>)\n",
      "tensor([[392, 220, 418, 230]], dtype=torch.int32)\n",
      "tensor(11.7072, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([389.5783, 207.8942, 437.1583, 225.7728], grad_fn=<MeanBackward1>)\n",
      "tensor([[392, 219, 419, 229]], dtype=torch.int32)\n",
      "tensor(8.7282, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([384.3044, 208.1859, 431.7931, 227.8136], grad_fn=<MeanBackward1>)\n",
      "tensor([[393, 219, 419, 229]], dtype=torch.int32)\n",
      "tensor(8.3723, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([380.5380, 209.1930, 426.8585, 230.3873], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 219, 420, 229]], dtype=torch.int32)\n",
      "tensor(7.8787, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([377.6550, 210.5901, 421.8130, 232.0559], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 219, 422, 229]], dtype=torch.int32)\n",
      "tensor(7.4994, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([376.3926, 212.8044, 418.7140, 233.4529], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 221, 422, 231]], dtype=torch.int32)\n",
      "tensor(8.1355, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([376.5596, 215.7554, 417.3223, 234.6194], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 221, 422, 231]], dtype=torch.int32)\n",
      "tensor(7.9955, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([377.9973, 219.3771, 417.4402, 235.5828], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 222, 422, 233]], dtype=torch.int32)\n",
      "tensor(6.9420, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([380.5735, 223.6148, 418.9030, 236.3607], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 223, 422, 233]], dtype=torch.int32)\n",
      "tensor(5.8748, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([383.7729, 227.0834, 421.1279, 236.7136], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 224, 423, 234]], dtype=torch.int32)\n",
      "tensor(5.2241, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([387.5408, 229.8586, 424.0463, 236.6792], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 223, 423, 234]], dtype=torch.int32)\n",
      "tensor(5.0108, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([391.0132, 231.5231, 425.5966, 235.7973], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 224, 424, 234]], dtype=torch.int32)\n",
      "tensor(4.2259, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([394.2139, 232.1830, 425.9152, 234.1590], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 223, 424, 234]], dtype=torch.int32)\n",
      "tensor(3.7608, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([397.1633, 231.9410, 425.1320, 231.8511], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 222, 424, 232]], dtype=torch.int32)\n",
      "tensor(3.0146, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.3327, 231.1572, 423.8501, 230.3175], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 221, 424, 231]], dtype=torch.int32)\n",
      "tensor(3.3306, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([402.6482, 229.9183, 423.2736, 229.5043], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 221, 425, 231]], dtype=torch.int32)\n",
      "tensor(3.9471, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([404.1982, 228.2718, 423.3256, 229.3341], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 221, 425, 230]], dtype=torch.int32)\n",
      "tensor(3.7026, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.0641, 226.2611, 423.9393, 229.7386], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 222, 426, 232]], dtype=torch.int32)\n",
      "tensor(3.6618, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.3206, 223.9264, 425.0578, 230.6585], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 221, 426, 231]], dtype=torch.int32)\n",
      "tensor(2.6327, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.0364, 221.3047, 426.6327, 232.0419], grad_fn=<MeanBackward1>)\n",
      "tensor([[400, 222, 426, 232]], dtype=torch.int32)\n",
      "tensor(1.6016, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([403.3938, 219.0331, 426.6103, 232.2553], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 222, 426, 232]], dtype=torch.int32)\n",
      "tensor(2.0566, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.5530, 217.0851, 425.1662, 231.4268], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 222, 425, 233]], dtype=torch.int32)\n",
      "tensor(2.0518, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([397.1009, 215.6664, 422.9332, 230.9900], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 223, 425, 233]], dtype=torch.int32)\n",
      "tensor(3.0774, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([395.8042, 215.6085, 422.8070, 231.8579], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 221, 424, 232]], dtype=torch.int32)\n",
      "tensor(2.2306, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([396.3707, 216.7380, 424.5077, 233.8697], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 222, 424, 232]], dtype=torch.int32)\n",
      "tensor(2.3172, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([397.3651, 218.2588, 425.4730, 235.1346], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 223, 425, 233]], dtype=torch.int32)\n",
      "tensor(2.2459, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([398.7462, 220.1318, 425.7739, 235.7250], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 222, 424, 232]], dtype=torch.int32)\n",
      "tensor(2.0283, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([398.6633, 221.8986, 424.6664, 235.2586], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 222, 425, 232]], dtype=torch.int32)\n",
      "tensor(1.0076, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([399.8757, 224.4344, 425.0082, 234.7662], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 221, 426, 231]], dtype=torch.int32)\n",
      "tensor(2.2670, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.0348, 225.9628, 425.4051, 233.5607], grad_fn=<MeanBackward1>)\n",
      "tensor([[400, 221, 425, 230]], dtype=torch.int32)\n",
      "tensor(2.2408, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([398.4695, 226.1408, 423.9774, 231.2672], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 231, 435, 241]], dtype=torch.int32)\n",
      "tensor(8.2863, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([398.7585, 227.4837, 424.4646, 230.4117], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 435, 242]], dtype=torch.int32)\n",
      "tensor(8.4704, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.6707, 229.8588, 426.6285, 230.8142], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 435, 243]], dtype=torch.int32)\n",
      "tensor(7.0069, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([404.0158, 233.1582, 430.2725, 232.3293], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 436, 243]], dtype=torch.int32)\n",
      "tensor(4.6352, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([408.2733, 236.0271, 434.8460, 234.6304], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 436, 244]], dtype=torch.int32)\n",
      "tensor(3.9560, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([411.6182, 238.1067, 439.5452, 237.2599], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 436, 244]], dtype=torch.int32)\n",
      "tensor(5.2525, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([413.3562, 239.0170, 442.4600, 239.7449], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 436, 244]], dtype=torch.int32)\n",
      "tensor(6.0221, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([413.6497, 238.8743, 443.7635, 242.0994], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 437, 244]], dtype=torch.int32)\n",
      "tensor(5.5470, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([412.6535, 237.7910, 443.6227, 244.3313], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 437, 243]], dtype=torch.int32)\n",
      "tensor(4.8496, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([410.1207, 235.6495, 441.7723, 245.1386], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 437, 243]], dtype=torch.int32)\n",
      "tensor(3.6703, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([406.2562, 232.5933, 438.4324, 244.6829], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 437, 243]], dtype=torch.int32)\n",
      "tensor(0.9912, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([401.2471, 228.7546, 433.8042, 243.1181], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 437, 243]], dtype=torch.int32)\n",
      "tensor(2.8280, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([397.9463, 226.2216, 430.8926, 241.5968], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 437, 243]], dtype=torch.int32)\n",
      "tensor(5.3357, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([396.5479, 225.0605, 429.9267, 241.3785], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 232, 437, 243]], dtype=torch.int32)\n",
      "tensor(6.2716, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([396.8186, 225.1039, 430.6716, 242.3102], grad_fn=<MeanBackward1>)\n",
      "tensor([[406, 233, 437, 244]], dtype=torch.int32)\n",
      "tensor(6.2739, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([398.5657, 226.2154, 432.9310, 244.2667], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 233, 437, 245]], dtype=torch.int32)\n",
      "tensor(4.5053, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([401.6282, 228.2838, 436.5413, 247.1444], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 234, 437, 245]], dtype=torch.int32)\n",
      "tensor(2.9228, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.5247, 231.0194, 440.9872, 249.6087], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 234, 437, 247]], dtype=torch.int32)\n",
      "tensor(2.5253, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([407.8626, 233.6395, 443.7646, 250.9067], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 236, 437, 247]], dtype=torch.int32)\n",
      "tensor(4.2236, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([408.7910, 236.1538, 445.0327, 251.1494], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 237, 436, 248]], dtype=torch.int32)\n",
      "tensor(4.4548, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([408.4537, 238.5674, 444.9436, 250.4450], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 238, 436, 249]], dtype=torch.int32)\n",
      "tensor(3.8524, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([406.6425, 239.6331, 443.2667, 248.6863], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 238, 436, 250]], dtype=torch.int32)\n",
      "tensor(3.2140, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([403.8860, 239.7010, 440.5745, 247.2547], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 239, 436, 250]], dtype=torch.int32)\n",
      "tensor(2.0337, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([401.9037, 239.2259, 437.6177, 246.4687], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 239, 435, 250]], dtype=torch.int32)\n",
      "tensor(1.8678, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.6092, 238.2709, 434.4303, 246.2557], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 239, 435, 250]], dtype=torch.int32)\n",
      "tensor(1.8585, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([400.9311, 238.5020, 433.1391, 247.1711], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 239, 435, 250]], dtype=torch.int32)\n",
      "tensor(1.8142, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([402.6881, 239.7881, 433.5207, 249.0943], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 238, 435, 249]], dtype=torch.int32)\n",
      "tensor(0.9184, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.0362, 240.5903, 434.6465, 250.4776], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 238, 435, 249]], dtype=torch.int32)\n",
      "tensor(1.6144, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([406.3071, 240.6033, 435.8107, 251.0067], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 237, 435, 248]], dtype=torch.int32)\n",
      "tensor(2.6819, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.9705, 239.5318, 435.3082, 250.3736], grad_fn=<MeanBackward1>)\n",
      "tensor([[402, 236, 435, 247]], dtype=torch.int32)\n",
      "tensor(2.7960, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([404.2108, 237.5051, 433.3311, 248.7136], grad_fn=<MeanBackward1>)\n",
      "tensor([[422, 217, 447, 225]], dtype=torch.int32)\n",
      "tensor(18.9192, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([403.3831, 235.3324, 432.3260, 246.8754], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 217, 447, 226]], dtype=torch.int32)\n",
      "tensor(17.8747, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([403.3918, 233.0321, 432.1942, 244.8817], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 218, 447, 227]], dtype=torch.int32)\n",
      "tensor(16.3320, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([404.1553, 230.6191, 432.8501, 242.7513], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 219, 447, 228]], dtype=torch.int32)\n",
      "tensor(14.3413, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([405.6039, 228.1054, 434.2206, 240.4995], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 221, 447, 228]], dtype=torch.int32)\n",
      "tensor(11.9451, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([407.6777, 225.5008, 436.2430, 238.1389], grad_fn=<MeanBackward1>)\n",
      "tensor([[421, 219, 447, 229]], dtype=torch.int32)\n",
      "tensor(9.9298, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([410.3251, 222.8136, 438.8641, 235.6802], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 219, 447, 229]], dtype=torch.int32)\n",
      "tensor(7.0761, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([413.5022, 220.0503, 442.0375, 233.1322], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 219, 447, 229]], dtype=torch.int32)\n",
      "tensor(4.1607, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([417.1711, 217.2161, 445.7240, 230.5019], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 219, 447, 229]], dtype=torch.int32)\n",
      "tensor(1.8477, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([421.6237, 215.4844, 450.2354, 227.9703], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 219, 447, 228]], dtype=torch.int32)\n",
      "tensor(2.1011, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([424.8176, 214.2558, 453.4604, 226.0083], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 219, 447, 229]], dtype=torch.int32)\n",
      "tensor(4.7535, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([426.8608, 213.4856, 455.5093, 224.5670], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 219, 447, 230]], dtype=torch.int32)\n",
      "tensor(6.8294, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([427.8566, 213.1298, 456.4880, 223.5978], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 220, 447, 230]], dtype=torch.int32)\n",
      "tensor(7.6543, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([427.9044, 213.1460, 456.4978, 223.0541], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 221, 448, 231]], dtype=torch.int32)\n",
      "tensor(8.0505, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([427.0994, 213.4943, 455.6354, 222.8918], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 221, 448, 232]], dtype=torch.int32)\n",
      "tensor(7.8372, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([425.5304, 214.1369, 453.9921, 223.0690], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 222, 448, 233]], dtype=torch.int32)\n",
      "tensor(7.3291, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([423.2811, 215.0386, 451.6537, 223.5469], grad_fn=<MeanBackward1>)\n",
      "tensor([[420, 222, 449, 233]], dtype=torch.int32)\n",
      "tensor(5.5873, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([420.4301, 216.1671, 448.6999, 224.2893], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 223, 448, 234]], dtype=torch.int32)\n",
      "tensor(4.6684, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([417.0501, 217.4928, 445.2053, 225.2634], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 223, 449, 234]], dtype=torch.int32)\n",
      "tensor(4.9971, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([415.5139, 219.6906, 443.6339, 227.1657], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 223, 449, 234]], dtype=torch.int32)\n",
      "tensor(4.7490, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([415.6078, 222.6799, 443.7628, 229.9067], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 223, 449, 234]], dtype=torch.int32)\n",
      "tensor(3.2607, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([417.1530, 226.3931, 445.4053, 233.4127], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 222, 449, 234]], dtype=torch.int32)\n",
      "tensor(2.6055, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([419.6799, 229.6061, 448.0633, 237.4411], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 223, 449, 235]], dtype=torch.int32)\n",
      "tensor(2.6659, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([421.1370, 231.8367, 450.6162, 240.4046], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 224, 450, 235]], dtype=torch.int32)\n",
      "tensor(3.9986, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([420.9542, 232.8011, 451.3532, 242.0105], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 224, 450, 236]], dtype=torch.int32)\n",
      "tensor(4.5298, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([419.3151, 232.6284, 450.4706, 242.3925], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 225, 450, 237]], dtype=torch.int32)\n",
      "tensor(3.4516, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([416.3915, 231.4440, 448.1522, 241.6817], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 226, 451, 237]], dtype=torch.int32)\n",
      "tensor(3.8955, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([414.5414, 230.0402, 446.8632, 240.7077], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 227, 451, 238]], dtype=torch.int32)\n",
      "tensor(3.5858, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([413.6505, 228.4435, 446.4955, 239.5030], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 227, 451, 239]], dtype=torch.int32)\n",
      "tensor(2.9501, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([413.6205, 226.6757, 446.9572, 238.0941], grad_fn=<MeanBackward1>)\n",
      "tensor([[419, 227, 451, 239]], dtype=torch.int32)\n",
      "tensor(2.6631, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([415.0344, 226.0956, 448.8899, 237.8636], grad_fn=<MeanBackward1>)\n",
      "tensor([[494, 194, 540, 211]], dtype=torch.int32)\n",
      "tensor(57.2587, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([417.0879, 225.2369, 451.4351, 237.3287], grad_fn=<MeanBackward1>)\n",
      "tensor([[499, 195, 546, 211]], dtype=torch.int32)\n",
      "tensor(58.2607, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([419.7266, 224.1252, 454.5418, 236.5180], grad_fn=<MeanBackward1>)\n",
      "tensor([[505, 196, 551, 213]], dtype=torch.int32)\n",
      "tensor(58.3437, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([422.9038, 222.7827, 458.1662, 235.4564], grad_fn=<MeanBackward1>)\n",
      "tensor([[511, 196, 556, 213]], dtype=torch.int32)\n",
      "tensor(58.7923, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([426.5786, 221.2289, 462.2713, 234.1660], grad_fn=<MeanBackward1>)\n",
      "tensor([[517, 197, 562, 215]], dtype=torch.int32)\n",
      "tensor(58.3862, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([430.7171, 219.4808, 466.8250, 232.6660], grad_fn=<MeanBackward1>)\n",
      "tensor([[522, 199, 567, 216]], dtype=torch.int32)\n",
      "tensor(57.1512, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([435.2893, 217.5534, 471.8001, 230.9732], grad_fn=<MeanBackward1>)\n",
      "tensor([[529, 199, 573, 217]], dtype=torch.int32)\n",
      "tensor(56.8593, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([440.2704, 215.4598, 477.1736, 229.1024], grad_fn=<MeanBackward1>)\n",
      "tensor([[534, 200, 578, 217]], dtype=torch.int32)\n",
      "tensor(55.5295, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([445.6387, 213.2112, 482.9262, 227.0667], grad_fn=<MeanBackward1>)\n",
      "tensor([[540, 201, 584, 219]], dtype=torch.int32)\n",
      "tensor(53.9283, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([451.3765, 210.8176, 489.0419, 224.8771], grad_fn=<MeanBackward1>)\n",
      "tensor([[545, 201, 589, 218]], dtype=torch.int32)\n",
      "tensor(52.5691, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([457.4688, 208.2874, 495.5067, 222.5435], grad_fn=<MeanBackward1>)\n",
      "tensor([[551, 201, 595, 218]], dtype=torch.int32)\n",
      "tensor(51.2138, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([463.9028, 205.6277, 502.3104, 220.0743], grad_fn=<MeanBackward1>)\n",
      "tensor([[557, 202, 601, 220]], dtype=torch.int32)\n",
      "tensor(48.8722, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([470.6689, 202.8445, 509.4441, 217.4762], grad_fn=<MeanBackward1>)\n",
      "tensor([[563, 200, 606, 217]], dtype=torch.int32)\n",
      "tensor(48.0519, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([477.7586, 199.9430, 516.9005, 214.7554], grad_fn=<MeanBackward1>)\n",
      "tensor([[569, 201, 611, 219]], dtype=torch.int32)\n",
      "tensor(47.6606, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([485.7613, 198.2600, 525.3193, 213.2683], grad_fn=<MeanBackward1>)\n",
      "tensor([[574, 200, 616, 218]], dtype=torch.int32)\n",
      "tensor(46.3478, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([494.6048, 197.6738, 534.6223, 212.8916], grad_fn=<MeanBackward1>)\n",
      "tensor([[579, 201, 620, 219]], dtype=torch.int32)\n",
      "tensor(44.8019, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([504.2267, 198.0831, 544.7429, 213.5224], grad_fn=<MeanBackward1>)\n",
      "tensor([[584, 201, 626, 219]], dtype=torch.int32)\n",
      "tensor(42.3562, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([514.5737, 199.4032, 555.6228, 215.0749], grad_fn=<MeanBackward1>)\n",
      "tensor([[589, 202, 630, 220]], dtype=torch.int32)\n",
      "tensor(39.0814, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([525.6000, 201.5631, 567.2131, 217.4769], grad_fn=<MeanBackward1>)\n",
      "tensor([[594, 201, 635, 219]], dtype=torch.int32)\n",
      "tensor(34.5683, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([537.0041, 203.2018, 579.1879, 220.5601], grad_fn=<MeanBackward1>)\n",
      "tensor([[599, 202, 640, 221]], dtype=torch.int32)\n",
      "tensor(31.1124, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([548.7790, 204.3468, 591.5405, 224.2851], grad_fn=<MeanBackward1>)\n",
      "tensor([[603, 202, 644, 221]], dtype=torch.int32)\n",
      "tensor(28.0781, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([560.6196, 204.9131, 603.9419, 227.2390], grad_fn=<MeanBackward1>)\n",
      "tensor([[607, 203, 648, 222]], dtype=torch.int32)\n",
      "tensor(24.3977, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([572.5451, 204.9382, 616.4138, 229.4748], grad_fn=<MeanBackward1>)\n",
      "tensor([[612, 205, 652, 224]], dtype=torch.int32)\n",
      "tensor(20.1444, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([584.8479, 205.8624, 629.2712, 231.1502], grad_fn=<MeanBackward1>)\n",
      "tensor([[616, 207, 657, 225]], dtype=torch.int32)\n",
      "tensor(16.5422, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([597.5205, 207.6257, 642.5069, 232.2959], grad_fn=<MeanBackward1>)\n",
      "tensor([[621, 208, 661, 226]], dtype=torch.int32)\n",
      "tensor(12.1607, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([610.5581, 210.1748, 656.1149, 232.9394], grad_fn=<MeanBackward1>)\n",
      "tensor([[625, 208, 665, 227]], dtype=torch.int32)\n",
      "tensor(7.8603, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([623.6820, 211.9724, 669.7964, 233.0024], grad_fn=<MeanBackward1>)\n",
      "tensor([[629, 209, 669, 228]], dtype=torch.int32)\n",
      "tensor(3.5223, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([635.9750, 212.7556, 681.1443, 232.1799], grad_fn=<MeanBackward1>)\n",
      "tensor([[633, 210, 673, 229]], dtype=torch.int32)\n",
      "tensor(4.2637, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([645.1252, 212.2991, 689.3372, 230.2167], grad_fn=<MeanBackward1>)\n",
      "tensor([[637, 209, 676, 228]], dtype=torch.int32)\n",
      "tensor(6.7445, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([651.4108, 210.7336, 694.6654, 227.2478], grad_fn=<MeanBackward1>)\n",
      "tensor([[641, 211, 681, 230]], dtype=torch.int32)\n",
      "tensor(6.7737, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([655.7220, 209.8420, 698.0688, 225.0717], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 194, 438, 206]], dtype=torch.int32)\n",
      "tensor(136.4261, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([657.6290, 207.9104, 699.0779, 221.9542], grad_fn=<MeanBackward1>)\n",
      "tensor([[405, 194, 437, 206]], dtype=torch.int32)\n",
      "tensor(136.1429, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([657.3850, 205.0625, 697.9515, 218.0161], grad_fn=<MeanBackward1>)\n",
      "tensor([[404, 194, 437, 206]], dtype=torch.int32)\n",
      "tensor(134.3538, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([655.2296, 201.4158, 694.9323, 213.3709], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 195, 436, 207]], dtype=torch.int32)\n",
      "tensor(130.9871, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([651.3862, 197.0803, 690.2461, 208.1237], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 195, 436, 207]], dtype=torch.int32)\n",
      "tensor(126.4591, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([646.0624, 192.1584, 684.1019, 202.3712], grad_fn=<MeanBackward1>)\n",
      "tensor([[403, 195, 436, 207]], dtype=torch.int32)\n",
      "tensor(124.6587, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([639.9561, 188.2843, 677.2274, 197.7494], grad_fn=<MeanBackward1>)\n",
      "tensor([[402, 195, 435, 207]], dtype=torch.int32)\n",
      "tensor(124.0374, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([633.1653, 185.3324, 669.7153, 194.1243], grad_fn=<MeanBackward1>)\n",
      "tensor([[401, 195, 435, 206]], dtype=torch.int32)\n",
      "tensor(122.1060, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([625.7807, 183.1889, 661.6520, 191.3748], grad_fn=<MeanBackward1>)\n",
      "tensor([[401, 194, 435, 206]], dtype=torch.int32)\n",
      "tensor(119.2172, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([617.8857, 181.7518, 653.1166, 189.3920], grad_fn=<MeanBackward1>)\n",
      "tensor([[401, 194, 435, 206]], dtype=torch.int32)\n",
      "tensor(115.9646, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([609.5571, 180.9291, 644.1816, 188.0779], grad_fn=<MeanBackward1>)\n",
      "tensor([[400, 194, 435, 206]], dtype=torch.int32)\n",
      "tensor(112.4329, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([600.8644, 180.6387, 634.9142, 187.3447], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 193, 434, 205]], dtype=torch.int32)\n",
      "tensor(108.1988, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([591.8721, 180.8067, 625.3749, 187.1137], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 193, 435, 205]], dtype=torch.int32)\n",
      "tensor(103.3317, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([582.6370, 181.3680, 615.6192, 187.3149], grad_fn=<MeanBackward1>)\n",
      "tensor([[399, 193, 435, 205]], dtype=torch.int32)\n",
      "tensor(98.3933, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([573.2126, 182.2638, 605.6973, 187.8860], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 193, 434, 205]], dtype=torch.int32)\n",
      "tensor(93.6900, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([563.6456, 183.4428, 595.6546, 188.7718], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 193, 435, 206]], dtype=torch.int32)\n",
      "tensor(88.2714, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([553.9791, 184.8594, 585.5317, 189.9232], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 194, 435, 206]], dtype=torch.int32)\n",
      "tensor(82.9321, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([544.2512, 186.4731, 575.3655, 191.2972], grad_fn=<MeanBackward1>)\n",
      "tensor([[398, 195, 435, 207]], dtype=torch.int32)\n",
      "tensor(77.7116, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([534.4960, 188.2489, 565.1891, 192.8559], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 196, 435, 209]], dtype=torch.int32)\n",
      "tensor(72.8950, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([524.7444, 190.1561, 555.0314, 194.5662], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 197, 434, 209]], dtype=torch.int32)\n",
      "tensor(67.5134, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([515.0231, 192.1679, 544.9188, 196.3993], grad_fn=<MeanBackward1>)\n",
      "tensor([[397, 197, 434, 210]], dtype=torch.int32)\n",
      "tensor(61.8437, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([505.3563, 194.2611, 534.8740, 198.3300], grad_fn=<MeanBackward1>)\n",
      "tensor([[396, 198, 433, 211]], dtype=torch.int32)\n",
      "tensor(56.9098, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([495.7652, 196.4156, 524.9179, 200.3368], grad_fn=<MeanBackward1>)\n",
      "tensor([[395, 199, 433, 212]], dtype=torch.int32)\n",
      "tensor(51.7327, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([486.2684, 198.6146, 515.0680, 202.4011], grad_fn=<MeanBackward1>)\n",
      "tensor([[394, 199, 432, 212]], dtype=torch.int32)\n",
      "tensor(46.3302, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([476.8818, 200.8435, 505.3397, 204.5070], grad_fn=<MeanBackward1>)\n",
      "tensor([[392, 198, 431, 212]], dtype=torch.int32)\n",
      "tensor(42.3895, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([467.3509, 201.9989, 495.4619, 206.5228], grad_fn=<MeanBackward1>)\n",
      "tensor([[391, 197, 430, 211]], dtype=torch.int32)\n",
      "tensor(37.8222, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([457.7192, 202.2114, 485.4790, 208.4400], grad_fn=<MeanBackward1>)\n",
      "tensor([[390, 196, 429, 210]], dtype=torch.int32)\n",
      "tensor(32.9924, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([448.0253, 201.6005, 475.4303, 210.2519], grad_fn=<MeanBackward1>)\n",
      "tensor([[388, 195, 428, 209]], dtype=torch.int32)\n",
      "tensor(28.8270, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([438.0324, 200.1499, 465.0631, 210.9108], grad_fn=<MeanBackward1>)\n",
      "tensor([[387, 194, 427, 208]], dtype=torch.int32)\n",
      "tensor(24.5391, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([427.8067, 197.9692, 454.4465, 210.5551], grad_fn=<MeanBackward1>)\n",
      "tensor([[386, 193, 426, 207]], dtype=torch.int32)\n",
      "tensor(19.6944, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([417.4075, 195.1589, 443.6419, 209.3124], grad_fn=<MeanBackward1>)\n",
      "tensor([[362, 210, 404, 226]], dtype=torch.int32)\n",
      "tensor(31.6445, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([407.4120, 192.8977, 433.2618, 208.4069], grad_fn=<MeanBackward1>)\n",
      "tensor([[360, 210, 401, 225]], dtype=torch.int32)\n",
      "tensor(28.3423, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([397.7960, 191.1124, 423.2806, 207.7920], grad_fn=<MeanBackward1>)\n",
      "tensor([[362, 211, 404, 226]], dtype=torch.int32)\n",
      "tensor(23.2931, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([388.5382, 189.7396, 413.6750, 207.4274], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 211, 405, 227]], dtype=torch.int32)\n",
      "tensor(18.7616, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([379.6188, 188.7247, 404.4243, 207.2785], grad_fn=<MeanBackward1>)\n",
      "tensor([[361, 210, 404, 225]], dtype=torch.int32)\n",
      "tensor(14.5100, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([371.0204, 188.0203, 395.5098, 207.3157], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 210, 405, 225]], dtype=torch.int32)\n",
      "tensor(14.2937, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([363.2846, 187.8743, 388.2507, 207.8329], grad_fn=<MeanBackward1>)\n",
      "tensor([[361, 209, 404, 225]], dtype=torch.int32)\n",
      "tensor(14.0817, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([356.3198, 188.2298, 382.4506, 208.7873], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 209, 406, 225]], dtype=torch.int32)\n",
      "tensor(16.8031, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([351.2743, 189.3157, 378.4962, 210.4499], grad_fn=<MeanBackward1>)\n",
      "tensor([[365, 209, 407, 225]], dtype=torch.int32)\n",
      "tensor(19.1160, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([347.9122, 191.0659, 376.1700, 212.7630], grad_fn=<MeanBackward1>)\n",
      "tensor([[364, 210, 406, 226]], dtype=torch.int32)\n",
      "tensor(19.5222, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([346.0368, 193.4250, 375.2883, 215.6768], grad_fn=<MeanBackward1>)\n",
      "tensor([[366, 210, 409, 226]], dtype=torch.int32)\n",
      "tensor(20.1433, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([345.4821, 196.3459, 375.6960, 219.1484], grad_fn=<MeanBackward1>)\n",
      "tensor([[366, 211, 409, 227]], dtype=torch.int32)\n",
      "tensor(19.0819, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([346.1084, 199.7881, 377.2619, 223.1408], grad_fn=<MeanBackward1>)\n",
      "tensor([[364, 213, 407, 228]], dtype=torch.int32)\n",
      "tensor(16.4252, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([347.7973, 203.7177, 379.8733, 227.6220], grad_fn=<MeanBackward1>)\n",
      "tensor([[364, 213, 407, 228]], dtype=torch.int32)\n",
      "tensor(13.2474, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([350.4485, 208.1052, 383.4346, 232.5640], grad_fn=<MeanBackward1>)\n",
      "tensor([[364, 212, 407, 228]], dtype=torch.int32)\n",
      "tensor(11.3939, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([353.6790, 212.7471, 387.5381, 236.9971], grad_fn=<MeanBackward1>)\n",
      "tensor([[367, 212, 411, 228]], dtype=torch.int32)\n",
      "tensor(11.6318, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([357.1686, 216.7067, 391.8410, 240.7769], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 212, 406, 227]], dtype=torch.int32)\n",
      "tensor(9.6185, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([360.9010, 220.0365, 396.3316, 243.9528], grad_fn=<MeanBackward1>)\n",
      "tensor([[365, 212, 409, 228]], dtype=torch.int32)\n",
      "tensor(10.1892, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([364.8618, 222.7854, 401.0010, 246.5718], grad_fn=<MeanBackward1>)\n",
      "tensor([[368, 212, 411, 228]], dtype=torch.int32)\n",
      "tensor(10.6236, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([369.0388, 224.9991, 405.8409, 248.6778], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 212, 407, 228]], dtype=torch.int32)\n",
      "tensor(10.2187, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([372.1323, 226.4252, 410.3098, 249.9856], grad_fn=<MeanBackward1>)\n",
      "tensor([[366, 213, 410, 228]], dtype=torch.int32)\n",
      "tensor(10.4632, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([373.6931, 226.8029, 413.0329, 250.2025], grad_fn=<MeanBackward1>)\n",
      "tensor([[366, 214, 410, 229]], dtype=torch.int32)\n",
      "tensor(11.1829, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([373.8729, 226.2387, 414.1747, 249.4411], grad_fn=<MeanBackward1>)\n",
      "tensor([[368, 214, 412, 230]], dtype=torch.int32)\n",
      "tensor(9.9318, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([372.8155, 224.8344, 413.8939, 247.8091], grad_fn=<MeanBackward1>)\n",
      "tensor([[369, 214, 413, 230]], dtype=torch.int32)\n",
      "tensor(8.3382, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([370.6571, 222.6874, 412.3412, 245.4082], grad_fn=<MeanBackward1>)\n",
      "tensor([[366, 213, 412, 228]], dtype=torch.int32)\n",
      "tensor(8.0235, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([367.5253, 219.8889, 409.6584, 242.3336], grad_fn=<MeanBackward1>)\n",
      "tensor([[369, 214, 413, 229]], dtype=torch.int32)\n",
      "tensor(6.0097, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([365.3105, 217.1094, 407.8641, 239.3190], grad_fn=<MeanBackward1>)\n",
      "tensor([[370, 213, 415, 229]], dtype=torch.int32)\n",
      "tensor(6.5635, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([363.9150, 214.3495, 406.8658, 236.3611], grad_fn=<MeanBackward1>)\n",
      "tensor([[363, 214, 408, 229]], dtype=torch.int32)\n",
      "tensor(2.4399, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([362.0041, 211.3336, 406.0543, 233.1513], grad_fn=<MeanBackward1>)\n",
      "tensor([[369, 214, 413, 229]], dtype=torch.int32)\n",
      "tensor(5.1898, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([361.1595, 209.3015, 406.2510, 230.2026], grad_fn=<MeanBackward1>)\n",
      "tensor([[369, 213, 414, 229]], dtype=torch.int32)\n",
      "tensor(5.1227, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([361.2719, 208.1439, 407.3589, 227.4809], grad_fn=<MeanBackward1>)\n",
      "tensor([[382, 191, 417, 204]], dtype=torch.int32)\n",
      "tensor(17.7485, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([361.9755, 206.8434, 408.9852, 224.7854], grad_fn=<MeanBackward1>)\n",
      "tensor([[381, 191, 417, 205]], dtype=torch.int32)\n",
      "tensor(15.6670, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([363.2177, 205.4149, 411.0872, 222.1116], grad_fn=<MeanBackward1>)\n",
      "tensor([[380, 191, 416, 204]], dtype=torch.int32)\n",
      "tensor(13.5554, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n",
      "tensor([364.9522, 203.8707, 413.6272, 219.4552], grad_fn=<MeanBackward1>)\n",
      "tensor([[379, 191, 416, 205]], dtype=torch.int32)\n",
      "tensor(10.9366, grad_fn=<MeanBackward0>)\n",
      "torch.Size([1, 500, 888])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "model = LPCNNv1()\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "LPCNNv1(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (rel1): ReLU()\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (rel2): ReLU()\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (dense): Linear(in_features=108240, out_features=128, bias=True)\n  (rel3): ReLU()\n  (bounding_box): Sequential(\n    (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (1): Linear(in_features=128, out_features=4, bias=True)\n  )\n)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = LPCNNv1()\n",
    "# model.load_from_checkpoint(r\"C:\\Users\\Arya\\workspace\\ProjectSentry\\data\\raw\\UFPR-ALPR dataset\\training\\lightning_logs\\version_48\\checkpoints\\epoch=0-step=1800.ckpt\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arya\\AppData\\Local\\Temp\\ipykernel_19740\\1225892266.py:4: MatplotlibDeprecationWarning: The close_event function was deprecated in Matplotlib 3.6 and will be removed two minor releases later. Use callbacks.process('close_event', CloseEvent(...)) instead.\n",
      "  plt.close()\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div id='6590c4a6-1172-4b8a-a32e-7c31c1116bf0'></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500, 888])\n",
      "tensor([380.0337, 227.2269, 413.6375, 236.2407])\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:/Users/Arya/workspace/ProjectSentry/data/raw/UFPR-ALPR dataset/training/track0028\")\n",
    "resize=torchvision.transforms.Resize(size=500)\n",
    "grayscale=torchvision.transforms.Grayscale()\n",
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "image = Image.open(\"track0028[01].png\")\n",
    "image = Image.fromarray(np.asarray(resize(image)))\n",
    "image = Image.fromarray(np.asarray(grayscale(image)))\n",
    "ax.imshow(image, cmap='gray')\n",
    "\n",
    "image = torch.tensor(np.asarray(image), dtype=torch.float32)\n",
    "bb = model(image[None, :]).detach().mean(axis=0)\n",
    "print(bb)\n",
    "x_min, y_min, x_max, y_max = bb\n",
    "rect = patches.Rectangle((x_min, y_min),x_max-x_min, y_max-y_min, linewidth=.5, edgecolor='r', facecolor='none' )\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
